# Études de cas — Process Engineering

## Cas 1 : Amélioration des métriques DORA d'une équipe engineering

### Contexte
DataVault, éditeur SaaS de data governance (90 personnes, 25 développeurs en 5 squads), aide les entreprises à cataloguer, classifier et protéger leurs données sensibles. L'entreprise est positionnée sur le segment mid-market européen, en compétition avec des acteurs américains comme Collibra et Alation, avec un différenciateur sur la conformité RGPD native. DataVault mesure ses métriques DORA pour la première fois lors d'un assessment engineering commandé par le nouveau VP Engineering. L'entreprise utilise Jira pour le project management, GitHub pour le code, et déploie sur AWS via un pipeline Jenkins custom maintenu par un unique SRE (point de défaillance critique). Le stack technique comprend Java Spring Boot (backend), React (frontend), PostgreSQL, et Elasticsearch.

### Problème
Les résultats DORA de l'assessment sont alarmants et placent DataVault dans la catégorie la plus basse : deployment frequency de 1 release/mois (batch monolithique de 80-120 PRs accumulées), lead time for changes de 21 jours (du commit au production), change failure rate de 22% (1 release sur 5 nécessite un hotfix dans les 48h), MTTR de 6 heures (debugging difficile car trop de changements par release rendent l'identification de la root cause quasi-impossible). L'équipe est classée "Low performer" selon le benchmark DORA — dans le quartile inférieur de l'industrie. Les développeurs sont frustrés par les cycles longs, les releases stressantes (chaque release nécessite une soirée de "war room"), et la déconnexion entre leur code et sa mise en production. Le turnover développeur atteint 20% annuel, et les entretiens de départ citent systématiquement la lenteur des cycles comme facteur de frustration.

### Approche
1. **Diagnostic du value stream** : Mapping complet du flux de livraison avec timestamps réels collectés sur 10 releases consécutives : coding (3 jours actifs) → PR review (5 jours d'attente en file) → QA manual testing (4 jours de tests de régression manuels par 2 QA) → staging deployment (2 jours incluant la résolution de problèmes d'environnement) → change advisory board approval (3 jours d'attente pour la réunion hebdomadaire du CAB) → production deployment (4 jours incluant la coordination et le créneau de déploiement). Le ratio temps actif/temps d'attente est de 25%/75% — seulement 5 jours de travail productif pour 21 jours de lead time. La visualisation du value stream (poster affiché dans l'open space) a créé un choc salutaire dans l'équipe et le management.
2. **Élimination des bottlenecks** : Suppression du QA manual testing de 4 jours (remplacé par des tests automatisés en CI : 800 tests unitaires, 200 tests d'intégration, 50 tests E2E Playwright couvrant les parcours critiques), suppression du change advisory board de 3 jours (remplacé par des quality gates automatisés en CI : lint, tests, security scan, coverage check — si le CI est vert, le code est déployable), migration Jenkins → GitHub Actions avec des pipelines standardisés par template (un pipeline par squad, identique, maintenable). L'équipe QA de 2 personnes est réorientée vers les tests exploratoires et la validation UX, à plus forte valeur ajoutée.
3. **Trunk-based development** : Migration du GitFlow (branches develop, release, hotfix avec des merges manuels entre branches) vers le trunk-based development. PRs limitées à 200 lignes de diff, feature flags (Unleash, self-hosted) pour découpler deploy de release, branches de vie < 1 jour. Le changement a nécessité 3 semaines de coaching avec un consultant externe spécialisé en trunk-based development, incluant des sessions de live-coding avec chaque squad pour montrer le workflow en conditions réelles. La résistance initiale ("c'est trop risqué de merger sur main") a été surmontée par la démonstration que les feature flags + quality gates offrent plus de sécurité que le GitFlow.
4. **Engineering metrics dashboard** : Déploiement de LinearB (évalué contre Sleuth et Jellyfish) pour mesurer en continu les DORA metrics, cycle time par PR, PR review time, et coding time par développeur. Dashboard visible par tous dans un écran dédié dans l'open space, rafraîchi en temps réel. Revue hebdomadaire des tendances en retrospective de squad avec un focus sur les anomalies (PR bloquée > 2 jours, cycle time en hausse). Le VP Engineering revue les métriques agrégées mensuellement avec le leadership team et les corrèle avec le delivery des features produit.

### Résultat
- Deployment frequency passée de 1/mois à 8/semaine (x32), chaque squad déployant indépendamment 1-2 fois par jour
- Lead time réduit de 21 jours à 1.8 jour (divisé par 12), dont 80% est du temps de travail actif (ratio inversé)
- Change failure rate réduit de 22% à 4% (releases plus petites = moins de risque, problèmes détectés plus rapidement)
- MTTR réduit de 6h à 35 min (rollback rapide + changements isolés = root cause identifiable en minutes)
- Classification DORA passée de "Low" à "Elite" en 6 mois — dans le top 15% de l'industrie
- Developer satisfaction (survey anonyme) passée de 3.5/10 à 8/10, et le turnover développeur est tombé à 5% sur les 6 mois suivants

### Leçons apprises
- Le value stream mapping révèle que 75% du lead time est du temps d'attente, pas du temps de travail — les plus gros gains viennent de l'élimination des queues et des approbations manuelles (QA manuel, CAB). Chez DataVault, la suppression du CAB a libéré 3 jours de lead time sans aucune dégradation de la qualité — les quality gates automatisés sont plus fiables qu'un comité humain de 30 minutes.
- Le trunk-based development est le catalyseur principal des métriques DORA elite — il force des PRs petites, des tests robustes, et un déploiement continu. Mais il nécessite un investissement préalable en tests automatisés et en feature flags. Chez DataVault, les 3 premières semaines ont été consacrées au renforcement des tests avant de migrer le workflow.
- Les métriques DORA doivent être visibles et discutées en équipe — la transparence crée l'élan d'amélioration. Chez DataVault, l'affichage public du dashboard a créé une dynamique de saine compétition entre les squads (la squad "Catalog" a été la première à atteindre le niveau Elite, motivant les autres).
- Les quality gates automatisés remplacent avantageusement les processus d'approbation manuelle — ils sont plus rapides (secondes vs jours), plus fiables (pas d'erreur humaine), et plus équitables (mêmes règles pour tous). Le seul cas où l'approbation humaine reste nécessaire est le changement d'infrastructure à fort impact.

---

## Cas 2 : Programme d'onboarding développeur accéléré

### Contexte
FinBridge, fintech de 60 personnes en hypercroissance (x3 en effectif sur 18 mois), embauche 15 développeurs en 6 mois pour accompagner une expansion européenne et le lancement de 3 nouveaux produits. L'équipe existante de 20 développeurs travaille sur un monolithe TypeScript/Next.js avec Supabase, déployé sur Vercel. L'entreprise opère dans le secteur du banking-as-a-service, avec des exigences de conformité réglementaire (PSD2) et de sécurité élevées. Il n'existe aucun processus d'onboarding formalisé — chaque nouveau développeur est "parrainé" par un senior qui lui montre le codebase pendant 2-3 semaines, de manière non structurée et variable selon le parrain. La documentation technique est dispersée entre Notion (50 pages, dont 60% obsolètes), un wiki Confluence abandonné, et des commentaires dans le code.

### Problème
Le time-to-first-commit (premier commit en production) est de 4 semaines en moyenne, avec des extrêmes allant de 2 semaines (développeur parrainé par un senior expérimenté) à 7 semaines (développeur parrainé par un senior débordé). Les seniors passent 40% de leur temps à onboarder, réduisant leur productivité sur le delivery et l'architecture — un coût caché estimé à 200K EUR/an. Les nouveaux développeurs posent les mêmes questions répétitives (comment configurer l'env local avec Supabase, comment déployer sur Vercel, où trouver la doc de l'API bancaire, comment tester les webhooks Stripe en local) — chaque senior répond aux mêmes 30 questions. Le turnover des nouveaux est de 25% dans les 6 premiers mois — les exit interviews citent la frustration de l'onboarding (sentiment d'être un fardeau, manque d'autonomie, documentation inexistante) comme raison principale.

### Approche
1. **Devcontainer standardisé** : Création d'un `.devcontainer` Docker avec toutes les dépendances pré-configurées (Node.js 20, PostgreSQL local, Redis, Supabase CLI avec seed data réaliste, extensions VS Code recommandées, outils de debugging, Stripe CLI pour les webhooks locaux). Le nouvel arrivant clone le repo, ouvre dans VS Code avec l'extension Remote Containers ou GitHub Codespaces, et a un environnement fonctionnel en < 10 minutes — identique à celui de tous les autres développeurs. Le devcontainer est testé en CI à chaque modification pour garantir qu'il fonctionne toujours. Un script `seed.sh` injecte des données de test réalistes (comptes bancaires fictifs, transactions, utilisateurs) pour que le développeur puisse explorer l'application immédiatement.
2. **Documentation-as-code** : Migration de la documentation depuis Notion (désynchronisée et dispersée) vers le repo (Markdown dans le répertoire `/docs`). Structure standardisée : `/docs/getting-started.md` (guide pas-à-pas du premier jour), `/docs/architecture/` (ADR et schémas d'architecture), `/docs/runbooks/` (procédures opérationnelles), `/docs/adr/` (décisions techniques). Freshness checks automatisés via un GitHub Action hebdomadaire : un bot crée une issue si un document n'a pas été mis à jour depuis 90 jours alors que le code associé (même répertoire) a changé significativement. La migration a pris 2 semaines avec un développeur dédié, en vérifiant et mettant à jour chaque document.
3. **Onboarding pathway gamifié** : Création de 20 "quests" progressives dans un fichier `ONBOARDING.md` avec des checkboxes et des liens vers les ressources pertinentes : Quest 1 (jour 1) → configurer l'environnement via devcontainer et lancer l'app, Quest 2 → corriger un bug tagué "good first issue" (5 bugs pré-identifiés faciles), Quest 5 → shipper une feature derrière un feature flag en suivant le golden path, Quest 10 → faire une PR de > 100 lignes avec tests unitaires et d'intégration, Quest 15 → être reviewer sur 3 PRs et donner du feedback constructif, Quest 20 → présenter un tech talk de 15 minutes sur un sujet de son choix. Chaque quest complétée est célébrée dans le canal Slack #team-wins. Le pathway est mis à jour par le dernier développeur onboardé (il a la meilleure perspective sur ce qui manque).
4. **Buddy program structuré** : Chaque nouvel arrivant a un buddy (pas son manager, pas dans sa squad) pendant 30 jours. Le buddy consacre exactement 30 min/jour (pas plus, pour ne pas surcharger) pour un check-in structuré. Un template de check-in guide la conversation : blocages actuels (technique ou organisationnel), apprentissages du jour, feedback sur le processus d'onboarding, question du jour (le buddy oriente vers la documentation ou la bonne personne). Les buddies sont formés lors d'un workshop de 1h sur le mentorat efficace (écouter, orienter, ne pas faire à la place). Un rotation de buddies assure que chaque senior est buddy au maximum 1 fois par trimestre pour éviter la surcharge.

### Résultat
- Time-to-first-commit réduit de 4 semaines à 3 jours (divisé par 9), avec une variance réduite (tous les nouveaux sont entre 2 et 4 jours)
- Temps des seniors sur l'onboarding réduit de 40% à 10% (devcontainer + docs + quests remplacent 80% du pairing non structuré), libérant 6 jours-senior par semaine
- Turnover 6 mois des nouveaux réduit de 25% à 5% — les 15 développeurs recrutés sont tous encore en poste après 6 mois
- 100% des nouveaux développeurs complètent les 10 premières quests en < 2 semaines, avec un sentiment d'autonomie mesuré à 8/10 au survey de 2 semaines
- eNPS des nouveaux (survey anonyme à 30 jours) passé de +5 à +52, les nouveaux citant l'onboarding comme "la meilleure expérience d'onboarding de leur carrière"
- La documentation est maintenue à jour grâce aux freshness checks — les questions répétitives posées sur Slack ont chuté de 80%, mesurées par un comptage des threads #questions-tech

### Leçons apprises
- Le devcontainer est le ROI le plus élevé de l'onboarding — éliminer les 2-3 jours de "ça marche pas sur ma machine" transforme la première impression et le sentiment de productivité dès le jour 1. Chez FinBridge, avant le devcontainer, 100% des nouveaux rencontraient des problèmes de configuration ; après, 0%.
- La documentation dans le repo (pas dans un wiki séparé comme Notion ou Confluence) est la seule qui reste à jour — la proximité avec le code force la maintenance. Chez FinBridge, les documents dans Notion avaient un taux d'obsolescence de 60% en 6 mois ; les documents dans le repo ont un taux d'obsolescence de 5% grâce aux freshness checks.
- Le buddy program structuré est crucial — sans cadre, le buddy fait trop (devient un second manager) ou pas assez (un check-in le premier jour puis plus rien). Le template de 30 min/jour est le format optimal : suffisant pour débloquer, insuffisant pour créer une dépendance.
- Le pathway gamifié transforme l'onboarding de "passif" (on m'explique) à "actif" (je fais) — les quests créent un sentiment de progression mesurable qui combat le syndrome de l'imposteur des premières semaines. Le fait de célébrer chaque quest en public renforce l'intégration sociale.

---

## Cas 3 : Mise en place d'un processus RFC pour les décisions techniques

### Contexte
AdTech, plateforme de publicité programmatique (100 personnes, 30 développeurs répartis en 6 squads), évolue rapidement sur un marché hyper-compétitif dominé par Google et Meta. L'entreprise traite 2 milliards d'impressions publicitaires par jour avec un stack technique comprenant Go (backend haute performance), React (dashboard), Kafka (streaming), ClickHouse (analytics), et un déploiement multi-cloud (AWS + GCP). L'entreprise fait face à 5-8 décisions techniques majeures par mois : choix de base de données pour un nouveau use case, migration de framework, adoption d'un nouveau service cloud, changement d'architecture pour le real-time bidding. Les décisions sont prises en réunion informelle de 30 minutes entre 2-3 personnes (souvent le tech lead de la squad concernée et un collègue) et rarement documentées au-delà d'un message Slack.

### Problème
Des décisions techniques coûteuses sont prises sans consultation large ni analyse d'alternatives : migration vers MongoDB décidée par 2 développeurs backend (sans consulter l'équipe data qui avait des besoins relationnels complexes incompatibles avec un document store), adoption de Kubernetes décidée en 3 jours sans évaluer les alternatives serverless (le cluster K8s coûte 15K EUR/mois pour un usage qui aurait coûté 3K EUR en serverless), et remplacement de l'ORM sans migration plan détaillé (causant 3 semaines de régression). Les développeurs non-consultés découvrent les changements au moment de l'implémentation et contestent les choix — débats tardifs qui bloquent les sprints, rework coûteux (estimé à 45 jours-développeur sur 6 mois), et frustration des squads qui subissent des décisions prises par d'autres. L'absence de documentation rend impossible de comprendre pourquoi un choix a été fait 6 mois plus tard — le nouveau développeur qui hérite du code MongoDB ne sait pas pourquoi PostgreSQL a été écarté.

### Approche
1. **Processus RFC (Request for Comments)** : Toute décision ayant un impact sur plus de 2 équipes ou coûtant plus de 2 semaines-développeur nécessite une RFC. Template structuré en 8 sections : Problème (quel problème résout-on, avec des données), Contexte (état actuel, contraintes), Proposition (solution détaillée avec architecture, pseudo-code si nécessaire), Alternatives envisagées (minimum 2, avec avantages/inconvénients), Impact (équipes affectées, coût de migration, timeline), Plan d'implémentation (phases, rollback plan), Risques et mitigations, et Questions ouvertes. Le template force la rigueur : une RFC de moins de 500 mots est systématiquement renvoyée pour insuffisance.
2. **Workflow de review** : La RFC est soumise en PR sur le repo `engineering-rfcs`. Période de commentaire de 5 jours ouvrés — suffisamment longue pour permettre la réflexion asynchrone, suffisamment courte pour ne pas bloquer l'exécution. Minimum 2 reviewers de squads différentes (rotation automatique pour diversifier les perspectives). L'auteur doit répondre à chaque commentaire (résolution explicite, pas de commentaire ignoré). Décision finale par le tech lead concerné après la période de review, documentée dans la RFC avec les arguments retenus. Les RFC controversées (>10 commentaires contradictoires) sont escaladées au VP Engineering qui organise un atelier de 1h pour trancher.
3. **ADR pour les décisions finales** : Chaque RFC approuvée génère un ADR (Architecture Decision Record) résumant le contexte, la décision, les alternatives écartées et les conséquences attendues. Les ADR sont versionnés dans le repo `engineering-rfcs/decisions/` et peuvent être superseded par un nouvel ADR (l'ancien reste consultable avec un statut "Superseded by ADR-XXX"). Ce mécanisme crée une historique des décisions consultable : un développeur peut retracer l'évolution d'un choix technique sur 2 ans.
4. **Catalogue de décisions** : Un site statique (Docusaurus) auto-généré depuis les RFCs et ADR via un pipeline GitHub Actions, searchable en full-text, avec des tags par domaine (backend, frontend, infra, data, security) et par statut (proposed, accepted, rejected, superseded). Les développeurs consultent le catalogue avant de proposer une nouvelle RFC pour éviter les doublons et comprendre les décisions passées. Le catalogue est le premier lien dans le guide d'onboarding technique — les nouveaux développeurs lisent les 10 ADR les plus récents pour comprendre l'état de l'art technique de l'entreprise.

### Résultat
- 45 RFCs rédigées en 6 mois — 38 approuvées (dont 12 avec des modifications significatives issues de la review), 5 rejetées (économisant un estimé de 12 semaines-développeur de mauvais choix), 2 en cours de review
- Contestation tardive de décisions réduite de 80% — les désaccords s'expriment pendant la période de review de 5 jours, pas pendant l'implémentation. Le rework lié aux décisions contestées est passé de 45 jours-dev/semestre à 8 jours-dev/semestre
- Temps de la RFC au début de l'implémentation : 8 jours en médiane (5 jours de review + 3 jours d'itération) — un investissement qui évite des semaines de rework et de débats tardifs
- 100% des décisions techniques majeures documentées et traçables — fin des "pourquoi on a choisi ça ?" sans réponse
- Onboarding technique accéléré — les nouveaux développeurs lisent les RFCs et ADR pour comprendre l'histoire des choix, réduisant le temps de montée en compétence architecturale de 3 mois à 1 mois

### Leçons apprises
- Le processus RFC transforme les décisions techniques de "politique informelle" (celui qui parle le plus fort gagne) en "ingénierie rationnelle" (les arguments écrits et les données gagnent) — la qualité des décisions augmente significativement quand on oblige à écrire les alternatives et les trade-offs.
- La période de review de 5 jours semble lente mais évite les mois de rework — c'est un investissement massif en prévention. Chez AdTech, les 5 RFCs rejetées auraient coûté collectivement 12 semaines de développement si elles avaient été implémentées directement.
- Le catalogue searchable de décisions est aussi précieux que les décisions elles-mêmes — il évite de redébattre des sujets déjà tranchés. Chez AdTech, 8 RFCs ont été retirées par leur auteur après consultation du catalogue car la question avait déjà été tranchée par un ADR existant.
- Le seuil de déclenchement (>2 équipes OU >2 semaines-dev) doit être calibré soigneusement — trop bas et le processus ralentit tout, trop haut et les décisions coûteuses passent entre les mailles. Chez AdTech, le seuil a été ajusté après 2 mois (initialement fixé à 1 semaine-dev, relevé à 2 pour réduire le nombre de RFCs mineures).
