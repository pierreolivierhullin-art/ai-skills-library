# √âtudes de cas ‚Äî Code Excellence

## Cas 1 : R√©duction de la dette technique d'un legacy codebase

### Contexte
FinApp, startup fintech de 35 personnes, maintient une application de gestion de tr√©sorerie d√©velopp√©e en 4 ans. Le codebase TypeScript/React/Node.js compte 180K lignes de code avec une couverture de tests de 22%. La v√©locit√© de l'√©quipe (8 d√©veloppeurs) a chut√© de 40% en 18 mois. Chaque nouvelle feature n√©cessite des modifications dans 15-20 fichiers en moyenne.

### Probl√®me
Le code accumule une dette technique massive : 47 God Classes (> 500 lignes), duplication de logique m√©tier dans 3 couches diff√©rentes (API, services, composants React), et z√©ro test sur le module de calcul de tr√©sorerie pr√©visionnelle (le plus critique). Les bugs de r√©gression augmentent de 20% par trimestre. Le onboarding d'un nouveau d√©veloppeur prend 6 semaines avant le premier commit productif. Le CTO estime que 60% du temps de d√©veloppement est consacr√© √† la compr√©hension du code existant.

### Approche
1. **Diagnostic par hotspots** : Analyse de churn via `git log` (fichiers les plus modifi√©s) crois√©e avec la complexit√© cyclomatique (SonarQube). Identification de 12 fichiers "hotspots" responsables de 65% des bugs ‚Äî priorit√© absolue de refactoring.
2. **Tests de caract√©risation** : Avant tout refactoring, √©criture de 200+ tests de caract√©risation sur les modules critiques (calcul de tr√©sorerie, moteur de pricing, r√©conciliation bancaire) pour capturer le comportement existant. Mutation testing avec Stryker pour valider la qualit√© des tests (mutation score initial : 35%, cible : 80%).
3. **Refactoring incr√©mental** : Application syst√©matique du Boy Scout Rule + sessions d√©di√©es (20% du sprint). Extraction des God Classes en modules coh√©rents (principe SRP), introduction de Value Objects (Money, AccountId, DateRange) pour remplacer les primitives, mise en place du pattern Ports & Adapters pour isoler la logique m√©tier.
4. **Quality gates en CI** : Configuration de SonarQube avec des portes strictes : z√©ro nouveau code smell bloquant, couverture minimum de 80% sur le nouveau code, complexit√© cyclomatique < 10 par fonction.

### R√©sultat
- Couverture de tests pass√©e de 22% √† 68% en 6 mois (90%+ sur la logique m√©tier critique)
- Mutation score pass√© de 35% √† 78%
- Bugs de r√©gression r√©duits de 45% par trimestre
- V√©locit√© de l'√©quipe remont√©e de 40% (retour au niveau initial)
- Onboarding r√©duit de 6 semaines √† 2 semaines gr√¢ce √† la meilleure lisibilit√©
- Les 12 fichiers hotspots refactor√©s en modules de < 200 lignes avec responsabilit√©s claires

### Le√ßons apprises
- L'analyse de churn √ó complexit√© est le meilleur prioriseur de refactoring ‚Äî cibler les fichiers qui changent souvent ET qui sont complexes, pas la dette technique "th√©orique".
- Les tests de caract√©risation avant refactoring sont non-n√©gociables ‚Äî sans eux, le refactoring introduit plus de bugs qu'il n'en corrige.
- Le 20% du sprint d√©di√© au refactoring est un investissement rentable d√®s le 2√®me trimestre en v√©locit√© r√©cup√©r√©e.

---

## Cas 2 : Transformation TDD dans une √©quipe produit

### Contexte
CloudSecure, √©diteur SaaS de cybers√©curit√© (60 personnes, 15 d√©veloppeurs), d√©veloppe un dashboard de monitoring de s√©curit√© en React/TypeScript avec un backend Go. L'√©quipe ship des features rapidement mais accumule des bugs critiques en production : 12 incidents P1 en 3 mois, principalement sur la logique de d√©tection d'alertes et le scoring de risque.

### Probl√®me
L'√©quipe pratique le "test-after" ‚Äî les tests sont √©crits apr√®s le code, souvent sous pression de deadline, et se limitent √† valider les happy paths. Le module de scoring de risque (200 r√®gles m√©tier) a une couverture de 40% mais un mutation score de seulement 15% ‚Äî les tests existent mais ne valident rien de significatif. Les code reviews prennent 3 jours en moyenne car les PRs font 800-1200 lignes sans tests pertinents.

### Approche
1. **Formation TDD immersive** : Workshop de 3 jours avec un coach externe sur le cycle Red-Green-Refactor, kata de code (Bowling, Mars Rover, Banking), puis application sur le codebase r√©el. Focus sur le "outside-in TDD" adapt√© au d√©veloppement produit.
2. **Pair programming syst√©matique** : 2 semaines de pair programming obligatoire entre d√©veloppeurs form√©s et non-form√©s. Un d√©veloppeur senior "TDD champion" par squad pour accompagner la transition.
3. **Trunk-based development** : Migration du feature branching (branches de 5-10 jours) vers le trunk-based development avec branches < 1 jour et feature flags (LaunchDarkly). Les PRs passent de 800+ lignes √† 150-200 lignes.
4. **Mutation testing en CI** : Int√©gration de Stryker dans le pipeline CI avec un seuil minimum de mutation score de 70% sur le nouveau code. Les PRs qui baissent le mutation score sont bloqu√©es.

### R√©sultat
- Incidents P1 r√©duits de 12 √† 2 par trimestre (√∑6)
- Mutation score du module de scoring pass√© de 15% √† 82%
- Temps de code review r√©duit de 3 jours √† 4 heures (PRs plus petites, tests comme documentation)
- Les d√©veloppeurs reportent une confiance accrue : 85% se sentent "en s√©curit√©" pour refactorer (vs 20% avant)
- Temps de d√©veloppement par feature initialement +30% (apprentissage TDD), puis -15% apr√®s 3 mois (moins de bugs, moins de rework)

### Le√ßons apprises
- Le TDD n'est pas une pratique de test mais une pratique de design ‚Äî il force √† penser aux interfaces et aux comportements avant l'impl√©mentation.
- Le pair programming est le vecteur de transmission le plus efficace pour le TDD ‚Äî les formations seules ne suffisent pas.
- Le trunk-based development est le catalyseur naturel du TDD : des PRs petites et fr√©quentes n√©cessitent des tests solides pour maintenir la confiance.

---

## Cas 3 : Mise en place d'une culture de code review efficace

### Contexte
EduTech, scale-up EdTech de 45 personnes (18 d√©veloppeurs r√©partis en 3 squads), d√©veloppe une plateforme d'apprentissage en ligne. Le processus de code review existe mais est dysfonctionnel : les PRs stagnent 4-5 jours, les reviewers se concentrent sur le style plut√¥t que la logique, et les d√©veloppeurs juniors re√ßoivent des feedback peu constructifs ("c'est pas comme √ßa qu'on fait ici").

### Probl√®me
Le temps moyen de cycle (du premier commit au merge) est de 7 jours, dont 4-5 jours d'attente en review. Les reviewers approuvent sans commentaire ("LGTM" automatique) sur 40% des PRs. 3 d√©veloppeurs juniors envisagent de quitter l'entreprise, citant les reviews comme source principale de frustration. Les bugs en production augmentent car la review ne d√©tecte que des probl√®mes cosm√©tiques.

### Approche
1. **Refonte du processus** : Limitation des PRs √† 400 lignes de diff maximum (exception document√©e au-del√†). Assignation automatique des reviewers par rotation via CODEOWNERS. SLA de review : premi√®re r√©ponse sous 4 heures ouvr√©es.
2. **Checklist de review structur√©e** : Introduction d'une checklist PR couvrant 10 crit√®res : logique m√©tier, s√©curit√© (OWASP), performance (N+1, pagination), tests (cas nominaux + edge cases), typage strict, error handling, accessibilit√©, r√©trocompatibilit√© API. Chaque reviewer doit valider chaque crit√®re explicitement.
3. **AI-assisted first pass** : D√©ploiement de CodeRabbit comme premier reviewer automatique. L'IA d√©tecte les probl√®mes de style, les code smells, les potentiels bugs et les violations de patterns. Les reviewers humains se concentrent sur la logique m√©tier, le design et les questions architecturales.
4. **Culture de feedback constructif** : Formation de 2 heures sur le feedback constructif en code review. R√®gle : chaque commentaire critique doit √™tre accompagn√© d'une suggestion concr√®te ou d'un exemple. Introduction de "comment types" : üî¥ Bloquant, üü° Suggestion, üí° Apprentissage.

### R√©sultat
- Cycle time r√©duit de 7 jours √† 1.5 jour (√∑4.7)
- Temps de premi√®re r√©ponse pass√© de 4-5 jours √† 3 heures
- PRs "LGTM sans commentaire" r√©duites de 40% √† 8%
- Bugs d√©tect√©s en review augment√©s de 3√ó (logique et s√©curit√© vs style)
- eNPS d√©veloppeur pass√© de -5 √† +32
- Z√©ro d√©part dans les 6 mois suivants ‚Äî les juniors citent les reviews comme source d'apprentissage

### Le√ßons apprises
- La taille des PRs est le facteur #1 de qualit√© de review ‚Äî au-del√† de 400 lignes, la qualit√© de relecture chute drastiquement.
- L'IA comme premier reviewer lib√®re les humains pour la r√©flexion de haut niveau ‚Äî mais ne remplace jamais le jugement humain sur la logique m√©tier.
- Le feedback constructif est une comp√©tence qui s'apprend ‚Äî investir dans la formation transforme la culture d'√©quipe en quelques semaines.
