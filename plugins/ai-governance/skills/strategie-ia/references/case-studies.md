# Études de cas — Stratégie IA & Gouvernance des Modèles

## Cas 1 : Création d'un Centre d'Excellence IA dans un grand groupe d'assurance

### Contexte
Groupe Prévoyance Européenne (GPE), acteur majeur de l'assurance en France avec 9 200 collaborateurs, 6,8 milliards d'euros de primes collectées et 4,2 millions d'assurés. L'entreprise opère sur les segments vie, santé, prévoyance et IARD, avec une présence dans 5 pays européens. Le paysage concurrentiel est marqué par l'émergence agressive d'insurtechs (Lemonade, Alan, Luko) qui captent les segments jeunes grâce à des parcours digitaux nativement alimentés par l'IA. La direction technologique comprend 420 collaborateurs, dont un département data de 28 personnes réparti entre 7 directions métier sans coordination centrale. Le groupe dispose de 23 initiatives IA dispersées dans ces 7 directions, mobilisant des stacks techniques hétérogènes (Python/scikit-learn, R, SAS, Azure ML, quelques notebooks Jupyter isolés). Le budget IA consolidé est de 14 M€/an mais le ROI global est jugé « non démontrable » par la direction financière, qui ne dispose d'aucun tableau de bord consolidé des retombées.

### Problème
L'absence de gouvernance centralisée génère une duplication massive des efforts : 4 équipes distinctes développent des modèles de scoring client avec des approches incompatibles et des données différentes, produisant des scores contradictoires pour un même assuré. Le time-to-market moyen d'un projet IA est de 14 mois (vs 6 mois chez les concurrents insurtechs), principalement en raison de l'absence de composants réutilisables et de processus de validation standardisés. 67 % des projets IA n'atteignent jamais la production (vs 46 % de moyenne sectorielle selon Gartner), souvent bloqués par des dépendances IT non anticipées ou un sponsorship métier insuffisant. Les 33 % déployés ne disposent d'aucun suivi de performance post-déploiement, créant un risque de dérive non détecté. Le turnover des profils data atteint 35 % annuels, les talents citant le manque de vision stratégique et l'isolement dans les directions métier comme principales raisons de départ. Le comité exécutif exige une restructuration complète de la stratégie IA avec résultats mesurables sous 18 mois.

### Approche
1. **Diagnostic et design organisationnel** : Audit de maturité IA sur 5 dimensions (stratégie, données, technologie, talents, gouvernance) selon le framework MIT/BCG, conduit sur 8 semaines par une équipe mixte interne/externe (3 consultants BCG + 5 managers internes). Score initial : 2,1/5. Conception d'un modèle hub-and-spoke : un Centre d'Excellence IA central de 35 personnes (CoE) coordonnant des relais IA intégrés dans chaque direction métier (18 data translators). Rattachement du CoE directement au COO pour garantir le mandat transverse et l'accès aux décisions d'investissement, après un débat arbitré par le CEO entre trois options de rattachement (DSI, CDO, COO).
2. **Constitution de l'équipe et montée en compétence** : Recrutement de 22 profils spécialisés (ML engineers, data engineers, MLOps, product managers IA) sur 6 mois, avec une stratégie de sourcing combinant cabinets spécialisés, cooptation et partenariats écoles (Polytechnique, CentraleSupélec, ENSAE). Reconversion interne de 13 collaborateurs issus de la DSI et de l'actuariat via un programme de 6 mois incluant formation technique, mentorat et immersion projet. Mise en place d'une IA Academy interne dispensant 4 niveaux de formation : sensibilisation (tous collaborateurs, 4h), praticien (métiers, 5 jours), expert (technique, 12 semaines), leader (comex, 2 jours). Objectif : 3 000 collaborateurs formés en 12 mois, avec un budget formation dédié de 1,2 M€.
3. **Plateforme et industrialisation** : Déploiement d'une plateforme ML mutualisée (Databricks + MLflow + Kubernetes) avec feature store partagé contenant 2 400 features documentées, catalogue de modèles réutilisables et pipelines CI/CD standardisés. L'infrastructure est dimensionnée pour supporter 50 projets IA simultanés et servir 200 modèles en production. Définition de 4 niveaux de criticité modèle avec processus de validation proportionnés (du self-service pour les modèles exploratoires à la validation comité pour les modèles réglementés), réduisant la charge de gouvernance tout en maintenant la rigueur sur les cas à enjeux. Réduction du time-to-market cible : 4 mois, grâce à la réutilisation des composants et à l'automatisation des étapes de validation technique.
4. **Gouvernance et pilotage par la valeur** : Création d'un AI Board trimestriel (CDO, CFO, CTO, directeurs métier) priorisant les cas d'usage par valeur business estimée et faisabilité technique, selon une matrice pondérée validée par le comex. Implémentation d'un framework de mesure du ROI IA avec 3 catégories : gains directs (automatisation, réduction de coûts), gains indirects (qualité de décision, réduction des erreurs), et valeur stratégique (avantage compétitif, rétention client). Tableau de bord mensuel consolidant 12 KPI couvrant la productivité du CoE, la performance des modèles en production, l'adoption par les métiers et le ROI financier. Un rapport trimestriel au conseil d'administration assure la visibilité du programme au plus haut niveau.

### Résultat
- Time-to-market moyen des projets IA réduit de 14 à 5,2 mois (-63 %)
- Taux de mise en production passé de 33 % à 71 % des projets initiés
- ROI IA démontrable de 23 M€ sur les 18 premiers mois (vs 14 M€ investis), soit un ratio de 1,64
- 2 850 collaborateurs formés via l'IA Academy, dont 340 certifiés praticien ou expert
- Turnover des profils data réduit de 35 % à 14 %, les collaborateurs citant la vision stratégique claire et la communauté de pratique comme facteurs de rétention
- Score de maturité IA passé de 2,1/5 à 3,6/5 en 18 mois, plaçant GPE dans le top 20 % des acteurs assurantiels européens selon le benchmark MIT/BCG

### Leçons apprises
- Le rattachement hiérarchique du CoE est déterminant : un rattachement à la DSI seul crée un biais technologique, tandis qu'un rattachement au COO ou au CDO garantit l'orientation business et le mandat transverse -- GPE a observé que le sponsorship COO a été décisif pour obtenir la coopération des directions métier réticentes
- Les data translators (profils hybrides métier/data) sont le maillon critique le plus sous-estimé : sans eux, la communication entre le CoE et les directions métier se dégrade en 3 mois, les projets dérivent vers des solutions techniquement élégantes mais déconnectées des besoins business réels
- La mutualisation du feature store a généré à elle seule 30 % des gains de productivité en éliminant la re-création de variables déjà calculées par d'autres équipes, un bénéfice inattendu qui justifie rétrospectivement d'investir dans l'infrastructure de données partagée dès le premier trimestre
- Le framework de mesure du ROI IA doit inclure des métriques non financières (adoption, satisfaction utilisateur, time-to-insight) pour capturer la valeur complète : les projets à ROI financier modeste mais à forte adoption génèrent souvent plus de valeur stratégique à moyen terme que les projets à fort ROI ponctuel mais faible adoption

---

## Cas 2 : Framework de décision Build vs Buy pour l'IA dans une entreprise de retail

### Contexte
Maisons Colbert, enseigne française de distribution spécialisée dans l'ameublement et la décoration, 3 800 salariés, 185 magasins et un site e-commerce représentant 28 % du chiffre d'affaires (1,2 Md€ total). L'entreprise fait face à une concurrence accrue d'acteurs pure-player (Made.com, Westwing) qui exploitent massivement l'IA pour la personnalisation et l'optimisation logistique. Le département technologique comprend 85 personnes, dont une équipe data de seulement 12 personnes (4 data scientists, 3 data engineers, 2 data analysts, 2 ML engineers, 1 manager) rattachée à la direction digitale. Le stack technique actuel repose sur Google Cloud Platform, BigQuery pour le data warehouse et des outils BI classiques (Looker). L'entreprise identifie 9 cas d'usage IA prioritaires (recommandation produit, pricing dynamique, prévision de demande, chatbot, détection de fraude, optimisation logistique, analyse d'avis clients, visual search, et personnalisation email) mais dispose d'un budget limité de 3,5 M€ et d'une capacité d'exécution contrainte.

### Problème
Sans cadre décisionnel, les 3 premiers projets IA sont lancés en mode « build from scratch » par l'équipe interne, mobilisant 100 % de la capacité pendant 9 mois sans livrer de valeur en production. Le moteur de recommandation, développé en interne, atteint 78 % de la performance du benchmark sectoriel mais consomme 65 % de la bande passante de l'équipe data. Le directeur digital exige simultanément un chatbot fonctionnel sous 3 mois et un moteur de recommandation sous 6 mois, des délais jugés irréalistes par l'équipe avec les ressources disponibles. L'équipe data est en burnout (turnover de 42 % sur 12 mois, 3 arrêts maladie longue durée), les délais explosent, et le comex commence à questionner l'investissement IA global. Le CFO fait circuler une note suggérant de réaffecter 50 % du budget IA vers des projets d'infrastructure classiques au ROI plus prévisible.

### Approche
1. **Conception du framework décisionnel** : Développement d'une matrice de décision Build/Buy/Partner évaluant chaque cas d'usage sur 8 critères pondérés : différenciation compétitive (25 %), disponibilité de solutions marché (15 %), complexité d'intégration (15 %), coût total sur 3 ans (15 %), time-to-value (10 %), dépendance données propriétaires (10 %), compétences requises vs disponibles (5 %), et risque réglementaire (5 %). Scoring de 1 à 5 par critère avec seuil de décision : Build si score > 3,5, Buy si < 2,5, Partner entre les deux. Le framework a été développé sur 2 semaines avec validation par un comité incluant le CDO, le CFO, le directeur achats et 2 directeurs métier, garantissant l'alignement inter-fonctionnel dès la conception.
2. **Évaluation systématique des 9 cas d'usage** : Ateliers de scoring réunissant équipe data, métiers, achats et direction financière sur 3 semaines, avec un facilitateur externe pour objectiver les débats. Benchmark de 28 solutions SaaS du marché avec évaluation sur critères fonctionnels, techniques (API, intégrabilité, performance), commerciaux (pricing, SLA, réversibilité) et stratégiques (roadmap, solidité financière du fournisseur). Résultat : 2 cas en Build (recommandation produit, prévision de demande -- forte dépendance aux données propriétaires et différenciation compétitive), 4 cas en Buy (chatbot, détection de fraude, analyse d'avis, personnalisation email), 3 cas en Partner (pricing dynamique, visual search, optimisation logistique -- nécessitant une expertise externe combinée aux données internes).
3. **Plan d'exécution séquencé** : Déploiement en 3 vagues sur 18 mois, conçu pour maximiser la vélocité des quick wins tout en préservant la capacité de l'équipe pour les projets Build stratégiques. Vague 1 (mois 1-4) : achats SaaS rapides (chatbot Intercom + module IA, fraude Signifyd) pour démontrer la valeur IA immédiate au comex avec un investissement limité. Vague 2 (mois 3-10) : Build recommandation et prévision avec l'équipe interne libérée des sujets Buy, en s'appuyant sur les données propriétaires de 2,8 millions de clients et 15 millions de transactions annuelles. Vague 3 (mois 8-18) : partenariats avec intégrateurs spécialisés pour pricing et logistique, nécessitant un travail d'intégration plus profond avec les systèmes existants (ERP, WMS).
4. **Gouvernance fournisseurs et réversibilité** : Négociation systématique de clauses de réversibilité (export des données et modèles), SLA de performance avec pénalités financières, et droits d'audit sur les solutions Buy, en collaboration avec la direction juridique et la direction achats. Mise en place d'un comité d'évaluation semestriel réévaluant chaque décision Buy/Build/Partner avec possibilité de bascule si le contexte évolue (compétences internes, maturité marché, budget). Un tableau de bord de suivi fournisseur trimestriel mesure la performance effective vs SLA contractuels, le coût total de possession réel vs estimé, et le niveau de dépendance technique, permettant des décisions de réversibilité éclairées.

### Résultat
- 6 cas d'usage en production en 12 mois (vs 0 sur les 9 mois précédents)
- Budget total consommé : 2,9 M€ sur 3,5 M€ alloués (économie de 17 %)
- ROI cumulé des 6 cas d'usage déployés : 5,2 M€/an (recommandation : +8 % de panier moyen, prévision : -23 % de ruptures, chatbot : -35 % d'appels niveau 1)
- Turnover de l'équipe data réduit de 42 % à 11 % grâce au recentrage sur les projets à forte valeur ajoutée
- Note de confiance du comex dans la stratégie IA passée de 2,8/5 à 4,3/5, le CFO retirant sa proposition de réallocation budgétaire après les résultats de la vague 1
- Le framework Build/Buy/Partner a été adopté comme standard de décision pour tous les projets technologiques du groupe, au-delà du périmètre IA initial

### Leçons apprises
- La décision Build vs Buy doit être réévaluée régulièrement : 2 des 4 cas initialement classés « Buy » ont été basculés en « Build » après 18 mois, lorsque l'équipe interne avait acquis suffisamment de maturité et que les solutions SaaS montraient leurs limites de personnalisation -- la flexibilité du framework est aussi importante que sa rigueur initiale
- Le séquencement « Quick wins Buy d'abord, Build stratégique ensuite » est essentiel pour maintenir le soutien du comex : la démonstration rapide de valeur achète le temps nécessaire aux projets Build plus longs, et Maisons Colbert estime que sans les résultats de la vague 1, le programme aurait été réduit de 50 %
- Le coût total de possession d'une solution Buy est systématiquement sous-estimé de 30 à 50 % si l'on ne comptabilise pas l'intégration, la personnalisation, la formation et la dépendance fournisseur : le chatbot Intercom, estimé à 120 K€/an, a coûté 195 K€ la première année en incluant l'intégration CRM et la personnalisation des workflows
- La protection de l'équipe data contre le burnout est un investissement stratégique, pas un luxe : le recentrage sur les projets Build à forte valeur ajoutée a restauré la motivation et la rétention, et les 3 collaborateurs arrêtés pour épuisement sont tous revenus après la restructuration du portefeuille de projets

---

## Cas 3 : Évaluation de maturité IA et feuille de route pour une banque de taille intermédiaire

### Contexte
Banque Rhône-Alpes Participations (BRAP), établissement bancaire régional de 1 600 collaborateurs avec 520 000 clients particuliers et 38 000 clients professionnels. L'actif sous gestion est de 18 Md€. Implantée principalement en Auvergne-Rhône-Alpes avec 78 agences, la banque se positionne sur la proximité client et le conseil personnalisé. L'environnement concurrentiel est marqué par la digitalisation accélérée des néobanques (Boursorama, Fortuneo, N26) et les investissements massifs en IA des grands groupes bancaires nationaux. La DSI de 95 personnes opère un SI bancaire core sur AS/400 progressivement migré vers des composants cloud (Azure). La banque dispose d'un département data de 8 personnes rattaché à la DSI, ayant livré 3 modèles de scoring (risque crédit, attrition, cross-sell) en production depuis 2 ans sur un stack Python/scikit-learn, mais sans stratégie IA formalisée ni vision à moyen terme.

### Problème
Le conseil d'administration mandate une évaluation complète de la maturité IA après que deux concurrents régionaux annoncent des investissements massifs en IA (12 M€ et 8 M€ respectivement). La BRAP craint un décrochage compétitif sur l'expérience client digitale et l'efficacité opérationnelle, d'autant que les enquêtes de satisfaction montrent un recul de 0,4 point en 12 mois sur les parcours digitaux. Le budget disponible est de 4,2 M€ sur 3 ans, nettement inférieur aux concurrents, imposant une stratégie de focalisation. Le régulateur (ACPR) renforce parallèlement ses attentes sur la gouvernance des modèles (guidelines EBA/ECB sur le risque modèle), avec une inspection programmée dans les 18 mois. L'équipe data de 8 personnes est en tension, sollicitée à 120 % de sa capacité entre maintenance des 3 modèles existants et demandes ad hoc des directions métier, sans priorisation claire ni visibilité sur les investissements futurs.

### Approche
1. **Évaluation de maturité structurée** : Déploiement du framework d'évaluation sur 6 dimensions : stratégie et vision (1,8/5), données et infrastructure (2,4/5), talents et compétences (2,0/5), gouvernance et éthique (1,5/5), cas d'usage et valeur (2,6/5), culture et adoption (1,9/5). Score global : 2,0/5 (« Émergent »). L'évaluation, conduite sur 6 semaines par un binôme interne-externe (directeur data + consultant Sia Partners), a impliqué 45 entretiens individuels couvrant les 6 directions métier, la DSI, la conformité et la direction générale. Benchmark détaillé avec 12 banques comparables européennes (moyenne secteur : 2,7/5). Identification de 3 gaps critiques : gouvernance (aucune politique IA formelle, aucun inventaire modèle), talents (8 personnes vs 14 nécessaires, compétences MLOps absentes), et infrastructure data (silos entre core banking, CRM et data warehouse, absence de data lake unifié).
2. **Priorisation des cas d'usage par valeur et faisabilité** : Identification de 22 cas d'usage potentiels via des ateliers avec les 6 directions métier, animés sur 2 semaines avec une méthodologie de design thinking adaptée. Évaluation selon une matrice impact business (0-100) vs faisabilité technique (0-100) vs exigence réglementaire, chaque cas d'usage étant évalué par un trinôme métier-data-risque pour garantir la pluralité des perspectives. Sélection de 8 cas d'usage prioritaires regroupés en 3 domaines : excellence opérationnelle (automatisation KYC, détection d'anomalies comptables, OCR documents), expérience client (conseiller augmenté, chatbot FAQ, next-best-action), et gestion des risques (early warning crédit, stress testing enrichi). Le processus de priorisation a permis d'éliminer 14 cas d'usage jugés soit trop coûteux, soit insuffisamment différenciants, soit trop risqués réglementairement pour le niveau de maturité actuel.
3. **Construction de la feuille de route triennale** : Phase 1 « Fondations » (mois 1-12, 1,4 M€) : recrutement de 6 profils clés (2 ML engineers, 1 data engineer, 1 MLOps engineer, 1 chef de projet IA, 1 data governance officer), déploiement d'un data lake unifié sur Azure intégrant les flux core banking, CRM et data warehouse, mise en place de la gouvernance modèle conforme EBA, et livraison de 3 quick wins (automatisation KYC, OCR, chatbot FAQ) choisis pour leur faisabilité élevée et leur visibilité métier. Phase 2 « Accélération » (mois 13-24, 1,6 M€) : déploiement de la plateforme MLOps (MLflow + Airflow), livraison de 3 cas d'usage avancés (conseiller augmenté, early warning, détection d'anomalies), formation de 400 collaborateurs. Phase 3 « Différenciation » (mois 25-36, 1,2 M€) : next-best-action, stress testing enrichi, et exploration IA générative.
4. **Cadre de gouvernance et conformité** : Rédaction d'une politique IA de 45 pages couvrant cycle de vie des modèles, gestion des risques modèle (MRM), éthique, et conformité réglementaire, validée par le comité des risques et le conseil d'administration. Création d'un comité modèle mensuel validant chaque mise en production, composé du directeur des risques, du directeur data, du responsable conformité et du directeur métier concerné. Mise en place d'un inventaire centralisé des modèles avec classification par niveau de risque (4 tiers), intégrant les 3 modèles existants et les 8 futurs modèles planifiés. Préparation à l'AI Act : cartographie des 8 cas d'usage selon la classification de risque européenne, identifiant 2 cas d'usage à haut risque (early warning crédit, KYC) nécessitant une documentation renforcée.

### Résultat
- Score de maturité IA passé de 2,0 à 3,3/5 en 24 mois (cible 3,8/5 à 36 mois)
- 6 cas d'usage en production à la fin de la phase 2, générant 3,1 M€ de valeur annuelle identifiée
- Automatisation KYC : réduction du temps de traitement de 35 minutes à 8 minutes par dossier, économie de 1,2 M€/an
- Conformité réglementaire : zéro observation majeure lors de l'inspection ACPR sur la gouvernance des modèles
- L'équipe data a doublé (de 8 à 16 personnes) avec un taux de rétention de 94 % sur la période, les recrues citant la clarté de la feuille de route comme facteur d'attractivité
- ROI cumulé du programme à 24 mois : 4,8 M€ de valeur générée pour 3,0 M€ investis, soit un ratio de 1,6 qui sécurise le financement de la phase 3 sans discussion au conseil d'administration

### Leçons apprises
- Pour une banque de taille intermédiaire, la stratégie de focalisation sur 6-8 cas d'usage à fort impact est plus rentable que la dispersion sur 20 initiatives : le budget limité impose une discipline de priorisation impitoyable, et la BRAP attribue son succès à la capacité de dire « non » à 14 des 22 cas d'usage identifiés
- La gouvernance des modèles n'est pas un frein mais un accélérateur : les processus de validation structurés réduisent le time-to-market en éliminant les allers-retours tardifs avec la conformité et le risque, et la BRAP estime que la politique IA a économisé 3 mois de délai cumulé sur les 6 premiers déploiements
- L'évaluation de maturité est un outil de communication interne puissant : la visualisation des gaps par rapport aux concurrents a été le déclencheur le plus efficace pour obtenir le sponsorship du conseil d'administration et l'adhésion des directions métier, transformant un sujet technique en enjeu stratégique compréhensible par tous
- L'investissement dans les fondations data (data lake unifié, qualité des données, gouvernance) est le facteur limitant numéro un : sans un socle de données fiable et accessible, même les meilleurs modèles et les meilleures équipes ne peuvent pas délivrer de valeur -- la BRAP a consacré 40 % du budget de la phase 1 à l'infrastructure data, un ratio que la direction juge rétrospectivement insuffisant
